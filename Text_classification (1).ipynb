{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 17:08:59,402 : INFO : using concatenative 12200-dimensional layer1\n",
      "2020-05-26 17:08:59,422 : INFO : collecting all words and their counts\n",
      "C:\\Users\\A\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "2020-05-26 17:08:59,451 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-05-26 17:08:59,486 : INFO : collected 2474 word types and 199 unique tags from a corpus of 199 examples and 6404 words\n",
      "2020-05-26 17:08:59,486 : INFO : Loading a fresh vocabulary\n",
      "2020-05-26 17:08:59,511 : INFO : effective_min_count=1 retains 2474 unique words (100% of original 2474, drops 0)\n",
      "2020-05-26 17:08:59,511 : INFO : effective_min_count=1 leaves 6404 word corpus (100% of original 6404, drops 0)\n",
      "2020-05-26 17:08:59,544 : INFO : deleting the raw counts dictionary of 2474 items\n",
      "2020-05-26 17:08:59,549 : INFO : sample=1e-06 downsamples 2474 most-common words\n",
      "2020-05-26 17:08:59,550 : INFO : downsampling leaves estimated 277 word corpus (4.3% of prior 6404)\n",
      "2020-05-26 17:08:59,575 : INFO : estimated required memory for 2474 words and 200 dimensions: 124106600 bytes\n",
      "2020-05-26 17:08:59,580 : INFO : resetting layer weights\n",
      "2020-05-26 17:08:59,680 : INFO : training model with 1 workers on 2475 vocabulary and 12200 features, using sg=0 hs=0 sample=1e-06 negative=10 window=30\n",
      "2020-05-26 17:09:00,125 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:00,133 : INFO : EPOCH - 1 : training on 6404 raw words (487 effective words) took 0.4s, 1104 effective words/s\n",
      "2020-05-26 17:09:00,221 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:00,224 : INFO : EPOCH - 2 : training on 6404 raw words (454 effective words) took 0.1s, 5418 effective words/s\n",
      "2020-05-26 17:09:00,312 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:00,313 : INFO : EPOCH - 3 : training on 6404 raw words (475 effective words) took 0.1s, 5867 effective words/s\n",
      "2020-05-26 17:09:00,395 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:00,397 : INFO : EPOCH - 4 : training on 6404 raw words (444 effective words) took 0.1s, 5742 effective words/s\n",
      "2020-05-26 17:09:00,487 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:00,492 : INFO : EPOCH - 5 : training on 6404 raw words (466 effective words) took 0.1s, 5392 effective words/s\n",
      "2020-05-26 17:09:00,591 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:00,593 : INFO : EPOCH - 6 : training on 6404 raw words (490 effective words) took 0.1s, 5215 effective words/s\n",
      "2020-05-26 17:09:00,676 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:00,678 : INFO : EPOCH - 7 : training on 6404 raw words (452 effective words) took 0.1s, 5884 effective words/s\n",
      "2020-05-26 17:09:00,759 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:00,763 : INFO : EPOCH - 8 : training on 6404 raw words (480 effective words) took 0.1s, 6133 effective words/s\n",
      "2020-05-26 17:09:00,841 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:00,844 : INFO : EPOCH - 9 : training on 6404 raw words (475 effective words) took 0.1s, 6437 effective words/s\n",
      "2020-05-26 17:09:00,923 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:00,926 : INFO : EPOCH - 10 : training on 6404 raw words (456 effective words) took 0.1s, 6233 effective words/s\n",
      "2020-05-26 17:09:01,044 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:01,046 : INFO : EPOCH - 11 : training on 6404 raw words (493 effective words) took 0.1s, 4987 effective words/s\n",
      "2020-05-26 17:09:01,137 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:01,140 : INFO : EPOCH - 12 : training on 6404 raw words (481 effective words) took 0.1s, 5550 effective words/s\n",
      "2020-05-26 17:09:01,221 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:01,226 : INFO : EPOCH - 13 : training on 6404 raw words (466 effective words) took 0.1s, 5869 effective words/s\n",
      "2020-05-26 17:09:01,316 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:01,319 : INFO : EPOCH - 14 : training on 6404 raw words (489 effective words) took 0.1s, 5825 effective words/s\n",
      "2020-05-26 17:09:01,427 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:01,430 : INFO : EPOCH - 15 : training on 6404 raw words (504 effective words) took 0.1s, 5013 effective words/s\n",
      "2020-05-26 17:09:01,537 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:01,540 : INFO : EPOCH - 16 : training on 6404 raw words (491 effective words) took 0.1s, 4955 effective words/s\n",
      "2020-05-26 17:09:01,627 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:01,630 : INFO : EPOCH - 17 : training on 6404 raw words (477 effective words) took 0.1s, 5943 effective words/s\n",
      "2020-05-26 17:09:01,720 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:01,722 : INFO : EPOCH - 18 : training on 6404 raw words (503 effective words) took 0.1s, 6071 effective words/s\n",
      "2020-05-26 17:09:01,805 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:01,808 : INFO : EPOCH - 19 : training on 6404 raw words (452 effective words) took 0.1s, 5831 effective words/s\n",
      "2020-05-26 17:09:01,905 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:01,909 : INFO : EPOCH - 20 : training on 6404 raw words (480 effective words) took 0.1s, 5352 effective words/s\n",
      "2020-05-26 17:09:02,007 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:02,010 : INFO : EPOCH - 21 : training on 6404 raw words (493 effective words) took 0.1s, 5190 effective words/s\n",
      "2020-05-26 17:09:02,104 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:02,109 : INFO : EPOCH - 22 : training on 6404 raw words (498 effective words) took 0.1s, 5448 effective words/s\n",
      "2020-05-26 17:09:02,204 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:02,206 : INFO : EPOCH - 23 : training on 6404 raw words (454 effective words) took 0.1s, 5128 effective words/s\n",
      "2020-05-26 17:09:02,304 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:02,305 : INFO : EPOCH - 24 : training on 6404 raw words (495 effective words) took 0.1s, 5394 effective words/s\n",
      "2020-05-26 17:09:02,386 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:02,391 : INFO : EPOCH - 25 : training on 6404 raw words (475 effective words) took 0.1s, 6196 effective words/s\n",
      "2020-05-26 17:09:02,476 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:02,478 : INFO : EPOCH - 26 : training on 6404 raw words (473 effective words) took 0.1s, 5693 effective words/s\n",
      "2020-05-26 17:09:02,573 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:02,575 : INFO : EPOCH - 27 : training on 6404 raw words (457 effective words) took 0.1s, 4887 effective words/s\n",
      "2020-05-26 17:09:02,678 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:02,680 : INFO : EPOCH - 28 : training on 6404 raw words (471 effective words) took 0.1s, 4689 effective words/s\n",
      "2020-05-26 17:09:02,781 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:02,786 : INFO : EPOCH - 29 : training on 6404 raw words (449 effective words) took 0.1s, 4711 effective words/s\n",
      "2020-05-26 17:09:02,905 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:02,908 : INFO : EPOCH - 30 : training on 6404 raw words (479 effective words) took 0.1s, 4159 effective words/s\n",
      "2020-05-26 17:09:03,012 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 17:09:03,017 : INFO : EPOCH - 31 : training on 6404 raw words (484 effective words) took 0.1s, 4608 effective words/s\n",
      "2020-05-26 17:09:03,119 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:03,121 : INFO : EPOCH - 32 : training on 6404 raw words (501 effective words) took 0.1s, 5253 effective words/s\n",
      "2020-05-26 17:09:03,206 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:03,212 : INFO : EPOCH - 33 : training on 6404 raw words (489 effective words) took 0.1s, 5619 effective words/s\n",
      "2020-05-26 17:09:03,308 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:03,311 : INFO : EPOCH - 34 : training on 6404 raw words (488 effective words) took 0.1s, 5260 effective words/s\n",
      "2020-05-26 17:09:03,426 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:03,429 : INFO : EPOCH - 35 : training on 6404 raw words (503 effective words) took 0.1s, 4462 effective words/s\n",
      "2020-05-26 17:09:03,529 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:03,531 : INFO : EPOCH - 36 : training on 6404 raw words (468 effective words) took 0.1s, 4787 effective words/s\n",
      "2020-05-26 17:09:03,618 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:03,622 : INFO : EPOCH - 37 : training on 6404 raw words (461 effective words) took 0.1s, 5441 effective words/s\n",
      "2020-05-26 17:09:03,706 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:03,708 : INFO : EPOCH - 38 : training on 6404 raw words (459 effective words) took 0.1s, 5606 effective words/s\n",
      "2020-05-26 17:09:03,800 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:03,803 : INFO : EPOCH - 39 : training on 6404 raw words (472 effective words) took 0.1s, 5311 effective words/s\n",
      "2020-05-26 17:09:03,894 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:03,898 : INFO : EPOCH - 40 : training on 6404 raw words (486 effective words) took 0.1s, 5483 effective words/s\n",
      "2020-05-26 17:09:04,007 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:04,012 : INFO : EPOCH - 41 : training on 6404 raw words (492 effective words) took 0.1s, 4599 effective words/s\n",
      "2020-05-26 17:09:04,118 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:04,119 : INFO : EPOCH - 42 : training on 6404 raw words (490 effective words) took 0.1s, 4784 effective words/s\n",
      "2020-05-26 17:09:04,201 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:04,202 : INFO : EPOCH - 43 : training on 6404 raw words (473 effective words) took 0.1s, 6116 effective words/s\n",
      "2020-05-26 17:09:04,274 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:04,276 : INFO : EPOCH - 44 : training on 6404 raw words (484 effective words) took 0.1s, 6877 effective words/s\n",
      "2020-05-26 17:09:04,353 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:04,354 : INFO : EPOCH - 45 : training on 6404 raw words (480 effective words) took 0.1s, 6447 effective words/s\n",
      "2020-05-26 17:09:04,434 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:04,437 : INFO : EPOCH - 46 : training on 6404 raw words (487 effective words) took 0.1s, 6299 effective words/s\n",
      "2020-05-26 17:09:04,504 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:04,509 : INFO : EPOCH - 47 : training on 6404 raw words (457 effective words) took 0.1s, 6787 effective words/s\n",
      "2020-05-26 17:09:04,586 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:04,588 : INFO : EPOCH - 48 : training on 6404 raw words (478 effective words) took 0.1s, 6253 effective words/s\n",
      "2020-05-26 17:09:04,668 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:04,671 : INFO : EPOCH - 49 : training on 6404 raw words (492 effective words) took 0.1s, 6331 effective words/s\n",
      "2020-05-26 17:09:04,748 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:04,749 : INFO : EPOCH - 50 : training on 6404 raw words (474 effective words) took 0.1s, 6389 effective words/s\n",
      "2020-05-26 17:09:04,824 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:04,827 : INFO : EPOCH - 51 : training on 6404 raw words (490 effective words) took 0.1s, 6556 effective words/s\n",
      "2020-05-26 17:09:04,900 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:04,907 : INFO : EPOCH - 52 : training on 6404 raw words (493 effective words) took 0.1s, 6499 effective words/s\n",
      "2020-05-26 17:09:04,975 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:04,981 : INFO : EPOCH - 53 : training on 6404 raw words (467 effective words) took 0.1s, 6738 effective words/s\n",
      "2020-05-26 17:09:05,050 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:05,051 : INFO : EPOCH - 54 : training on 6404 raw words (470 effective words) took 0.1s, 7064 effective words/s\n",
      "2020-05-26 17:09:05,124 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:05,127 : INFO : EPOCH - 55 : training on 6404 raw words (474 effective words) took 0.1s, 6517 effective words/s\n",
      "2020-05-26 17:09:05,201 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:05,204 : INFO : EPOCH - 56 : training on 6404 raw words (470 effective words) took 0.1s, 6395 effective words/s\n",
      "2020-05-26 17:09:05,269 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:05,286 : INFO : EPOCH - 57 : training on 6404 raw words (510 effective words) took 0.1s, 6627 effective words/s\n",
      "2020-05-26 17:09:05,360 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:05,361 : INFO : EPOCH - 58 : training on 6404 raw words (458 effective words) took 0.1s, 6341 effective words/s\n",
      "2020-05-26 17:09:05,433 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:05,439 : INFO : EPOCH - 59 : training on 6404 raw words (465 effective words) took 0.1s, 6379 effective words/s\n",
      "2020-05-26 17:09:05,511 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:05,513 : INFO : EPOCH - 60 : training on 6404 raw words (461 effective words) took 0.1s, 6486 effective words/s\n",
      "2020-05-26 17:09:05,584 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:05,591 : INFO : EPOCH - 61 : training on 6404 raw words (481 effective words) took 0.1s, 6564 effective words/s\n",
      "2020-05-26 17:09:05,657 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:05,662 : INFO : EPOCH - 62 : training on 6404 raw words (478 effective words) took 0.1s, 7155 effective words/s\n",
      "2020-05-26 17:09:05,725 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:05,729 : INFO : EPOCH - 63 : training on 6404 raw words (440 effective words) took 0.1s, 6875 effective words/s\n",
      "2020-05-26 17:09:05,797 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:05,799 : INFO : EPOCH - 64 : training on 6404 raw words (457 effective words) took 0.1s, 6999 effective words/s\n",
      "2020-05-26 17:09:05,871 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:05,877 : INFO : EPOCH - 65 : training on 6404 raw words (490 effective words) took 0.1s, 6590 effective words/s\n",
      "2020-05-26 17:09:05,943 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:05,949 : INFO : EPOCH - 66 : training on 6404 raw words (478 effective words) took 0.1s, 6945 effective words/s\n",
      "2020-05-26 17:09:06,017 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:06,020 : INFO : EPOCH - 67 : training on 6404 raw words (457 effective words) took 0.1s, 6797 effective words/s\n",
      "2020-05-26 17:09:06,093 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:06,099 : INFO : EPOCH - 68 : training on 6404 raw words (491 effective words) took 0.1s, 6576 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 17:09:06,166 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:06,168 : INFO : EPOCH - 69 : training on 6404 raw words (479 effective words) took 0.1s, 7266 effective words/s\n",
      "2020-05-26 17:09:06,250 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:06,260 : INFO : EPOCH - 70 : training on 6404 raw words (510 effective words) took 0.1s, 6068 effective words/s\n",
      "2020-05-26 17:09:06,352 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:06,358 : INFO : EPOCH - 71 : training on 6404 raw words (474 effective words) took 0.1s, 5159 effective words/s\n",
      "2020-05-26 17:09:06,446 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:06,451 : INFO : EPOCH - 72 : training on 6404 raw words (466 effective words) took 0.1s, 5260 effective words/s\n",
      "2020-05-26 17:09:06,534 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:06,540 : INFO : EPOCH - 73 : training on 6404 raw words (484 effective words) took 0.1s, 5702 effective words/s\n",
      "2020-05-26 17:09:06,620 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:06,633 : INFO : EPOCH - 74 : training on 6404 raw words (493 effective words) took 0.1s, 5564 effective words/s\n",
      "2020-05-26 17:09:06,723 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:06,725 : INFO : EPOCH - 75 : training on 6404 raw words (452 effective words) took 0.1s, 5226 effective words/s\n",
      "2020-05-26 17:09:06,793 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:06,797 : INFO : EPOCH - 76 : training on 6404 raw words (441 effective words) took 0.1s, 6498 effective words/s\n",
      "2020-05-26 17:09:06,884 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:06,890 : INFO : EPOCH - 77 : training on 6404 raw words (508 effective words) took 0.1s, 5788 effective words/s\n",
      "2020-05-26 17:09:07,018 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:07,023 : INFO : EPOCH - 78 : training on 6404 raw words (491 effective words) took 0.1s, 3775 effective words/s\n",
      "2020-05-26 17:09:07,097 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:07,100 : INFO : EPOCH - 79 : training on 6404 raw words (470 effective words) took 0.1s, 6475 effective words/s\n",
      "2020-05-26 17:09:07,172 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:07,174 : INFO : EPOCH - 80 : training on 6404 raw words (464 effective words) took 0.1s, 6579 effective words/s\n",
      "2020-05-26 17:09:07,238 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:07,240 : INFO : EPOCH - 81 : training on 6404 raw words (454 effective words) took 0.1s, 7190 effective words/s\n",
      "2020-05-26 17:09:07,316 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:07,319 : INFO : EPOCH - 82 : training on 6404 raw words (488 effective words) took 0.1s, 6572 effective words/s\n",
      "2020-05-26 17:09:07,394 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:07,395 : INFO : EPOCH - 83 : training on 6404 raw words (455 effective words) took 0.1s, 6254 effective words/s\n",
      "2020-05-26 17:09:07,476 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:07,479 : INFO : EPOCH - 84 : training on 6404 raw words (491 effective words) took 0.1s, 6238 effective words/s\n",
      "2020-05-26 17:09:07,546 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:07,551 : INFO : EPOCH - 85 : training on 6404 raw words (478 effective words) took 0.1s, 7040 effective words/s\n",
      "2020-05-26 17:09:07,620 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:07,622 : INFO : EPOCH - 86 : training on 6404 raw words (472 effective words) took 0.1s, 6927 effective words/s\n",
      "2020-05-26 17:09:07,687 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:07,695 : INFO : EPOCH - 87 : training on 6404 raw words (474 effective words) took 0.1s, 6947 effective words/s\n",
      "2020-05-26 17:09:07,767 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:07,769 : INFO : EPOCH - 88 : training on 6404 raw words (449 effective words) took 0.1s, 6284 effective words/s\n",
      "2020-05-26 17:09:07,845 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:07,847 : INFO : EPOCH - 89 : training on 6404 raw words (474 effective words) took 0.1s, 6469 effective words/s\n",
      "2020-05-26 17:09:07,917 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:07,919 : INFO : EPOCH - 90 : training on 6404 raw words (464 effective words) took 0.1s, 6797 effective words/s\n",
      "2020-05-26 17:09:07,993 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:07,996 : INFO : EPOCH - 91 : training on 6404 raw words (479 effective words) took 0.1s, 6466 effective words/s\n",
      "2020-05-26 17:09:08,066 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:08,068 : INFO : EPOCH - 92 : training on 6404 raw words (463 effective words) took 0.1s, 7069 effective words/s\n",
      "2020-05-26 17:09:08,138 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:08,140 : INFO : EPOCH - 93 : training on 6404 raw words (463 effective words) took 0.1s, 6696 effective words/s\n",
      "2020-05-26 17:09:08,212 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:08,216 : INFO : EPOCH - 94 : training on 6404 raw words (486 effective words) took 0.1s, 6756 effective words/s\n",
      "2020-05-26 17:09:08,292 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:08,297 : INFO : EPOCH - 95 : training on 6404 raw words (492 effective words) took 0.1s, 6474 effective words/s\n",
      "2020-05-26 17:09:08,367 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:08,374 : INFO : EPOCH - 96 : training on 6404 raw words (487 effective words) took 0.1s, 6534 effective words/s\n",
      "2020-05-26 17:09:08,452 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:08,453 : INFO : EPOCH - 97 : training on 6404 raw words (496 effective words) took 0.1s, 6582 effective words/s\n",
      "2020-05-26 17:09:08,525 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:08,532 : INFO : EPOCH - 98 : training on 6404 raw words (488 effective words) took 0.1s, 6646 effective words/s\n",
      "2020-05-26 17:09:08,604 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:08,607 : INFO : EPOCH - 99 : training on 6404 raw words (498 effective words) took 0.1s, 6971 effective words/s\n",
      "2020-05-26 17:09:08,680 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-26 17:09:08,684 : INFO : EPOCH - 100 : training on 6404 raw words (488 effective words) took 0.1s, 6524 effective words/s\n",
      "2020-05-26 17:09:08,685 : INFO : training on a 640400 raw words (47678 effective words) took 9.0s, 5296 effective words/s\n",
      "2020-05-26 17:09:08,686 : INFO : saving Doc2Vec object under task1_d2v_dm.model, separately None\n",
      "2020-05-26 17:09:08,689 : INFO : storing np array 'syn1neg' to task1_d2v_dm.model.trainables.syn1neg.npy\n",
      "C:\\Users\\A\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "2020-05-26 17:09:09,758 : INFO : saved task1_d2v_dm.model\n"
     ]
    }
   ],
   "source": [
    "#NOTE: Before running the notebook ensure that folder bbc, this notebook, and classify_text are in the same directory\n",
    "#doc2vec_PV-DM\n",
    "#Summary: PV-DM: Learns a model topredict the centre word of a randmly sampled context words and a paragraph vector. \n",
    "#Tries to learn the correct probability distribution for central words given the context words and the paragraph vector.\n",
    "#uses LSTM with RNN architecture to learn doc embeddings\n",
    "import gensim.models as gsm\n",
    "import logging as lg\n",
    "\n",
    "training_text = \"data_for_embeddings.txt\"\n",
    "#Model location\n",
    "d2v_dm_loc =\"d2v_dm.model\"\n",
    "#logging\n",
    "lg.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=lg.INFO)\n",
    "#training PV-DM model #dm=1\n",
    "text =gsm.doc2vec.TaggedLineDocument(training_text)\n",
    "doc2vec_dm_model =gsm.Doc2Vec(text, vector_size=200, window=30, min_count=1, sample=1e-6, workers=1, hs=0, dm=1, negative=10, dbow_words=1, dm_concat=1,ns_exponent=.75, epochs=100)\n",
    "#saving the model at the specified location\n",
    "doc2vec_dm_model.save(d2v_dm_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For task2: Trained a 3 layer deep NN to obtain a softmax output for 5 different classes. Train Accuraccy obtained about 90%.\n",
    "#Classify_text output business\n",
    "#embeddings used: doc2vec_PV-DM\n",
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 17:09:58,623 : INFO : loading Doc2Vec object from task1_d2v_dm.model\n",
      "C:\\Users\\A\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "2020-05-26 17:09:58,675 : INFO : loading vocabulary recursively from task1_d2v_dm.model.vocabulary.* with mmap=None\n",
      "2020-05-26 17:09:58,677 : INFO : loading trainables recursively from task1_d2v_dm.model.trainables.* with mmap=None\n",
      "2020-05-26 17:09:58,677 : INFO : loading syn1neg from task1_d2v_dm.model.trainables.syn1neg.npy with mmap=None\n",
      "2020-05-26 17:10:00,175 : INFO : loading wv recursively from task1_d2v_dm.model.wv.* with mmap=None\n",
      "2020-05-26 17:10:00,179 : INFO : loading docvecs recursively from task1_d2v_dm.model.docvecs.* with mmap=None\n",
      "2020-05-26 17:10:00,180 : INFO : loaded task1_d2v_dm.model\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "import os\n",
    "import gensim as gsm\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "model= Doc2Vec.load(\"d2v_dm.model\")\n",
    "X_train =[];\n",
    "for dirs in os.listdir(\"./bbc\"):\n",
    "    for file in os.listdir(\"./bbc/\"+dirs):\n",
    "        fh=open(\"./bbc/\"+dirs+'/'+file)\n",
    "        inp=fh.read()\n",
    "        X_train.append(model.infer_vector(word_tokenize(inp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225, 200)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225, 5)\n"
     ]
    }
   ],
   "source": [
    "c=0;\n",
    "Y_train=[]\n",
    "for dirs in os.listdir(\"./bbc\"):\n",
    "    a=np.zeros(5)\n",
    "    a[c]=1\n",
    "    for file in os.listdir(\"./bbc/\"+dirs):\n",
    "        Y_train.append(a)\n",
    "    c+=1;\n",
    "print(np.shape(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2225)\n",
      "(5, 2225)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train=np.transpose(X_train)\n",
    "print(np.shape(X_train))\n",
    "Y_train=np.transpose(Y_train)\n",
    "print(np.shape(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \n",
    "    #Creates the placeholders for the tensorflow session.\n",
    "    X = tf.placeholder(tf.float32,[n_x,None])\n",
    "    Y = tf.placeholder(tf.float32,[n_y,None])\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \n",
    "    #first hidden layer 25 hidden units\n",
    "    W1 = tf.get_variable(\"W1\",[25,200],initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b1 = tf.get_variable(\"b1\",[25,1],initializer=tf.zeros_initializer())\n",
    "    #second hidden layer 12 hidden units\n",
    "    W2 = tf.get_variable(\"W2\",[12,25],initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b2 = tf.get_variable(\"b2\",[12,1],initializer=tf.zeros_initializer())\n",
    "    #output layer 5 units\n",
    "    W3 = tf.get_variable(\"W3\",[5,12],initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b3 = tf.get_variable(\"b3\",[5,1],initializer=tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \n",
    "    #Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    #Activations         \n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                                             \n",
    "    A1 = tf.nn.relu(Z1)                                             \n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                                             \n",
    "    A2 = tf.nn.relu(Z2)                                             \n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                                              \n",
    "\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \n",
    "    #cost function\n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64):\n",
    "    \n",
    "    #Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    #np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, learning_rate = 0.001,\n",
    "          num_epochs = 1500, minibatch_size = 64, print_cost = True):\n",
    "    \n",
    "    #Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    #print_cost: True to print the cost every 100 epochs\n",
    "    #output: parameters: parameters learnt by the model. Used for prediction\n",
    "    \n",
    "    # to be able to rerun the model without overwriting tf variables\n",
    "    ops.reset_default_graph()                         \n",
    "                                             \n",
    "    (n_x, m) = X_train.shape                          \n",
    "    n_y = Y_train.shape[0]                            \n",
    "    \n",
    "    #tracking cost after every 100 epochs\n",
    "    costs = []                                        \n",
    "    \n",
    "    #Using all the above functions defined using tensorflow\n",
    "    X, Y = create_placeholders(n_x,n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    # Backpropagation: Optimiser: Adam\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       \n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost],feed_dict={X:minibatch_X, Y:minibatch_Y})\n",
    "                epoch_cost += minibatch_cost / minibatch_size\n",
    "\n",
    "            # Print the cost every 100 epochs\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per fives)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 17:18:01,631 : WARNING : \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "2020-05-26 17:18:02,100 : WARNING : From <ipython-input-10-49a7c2bda3d3>:8: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.878801\n",
      "Cost after epoch 100: 0.767180\n",
      "Cost after epoch 200: 0.726402\n",
      "Cost after epoch 300: 0.709835\n",
      "Cost after epoch 400: 0.684906\n",
      "Cost after epoch 500: 0.653975\n",
      "Cost after epoch 600: 0.629090\n",
      "Cost after epoch 700: 0.601082\n",
      "Cost after epoch 800: 0.572356\n",
      "Cost after epoch 900: 0.536861\n",
      "Cost after epoch 1000: 0.501920\n",
      "Cost after epoch 1100: 0.470170\n",
      "Cost after epoch 1200: 0.436755\n",
      "Cost after epoch 1300: 0.400942\n",
      "Cost after epoch 1400: 0.370321\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.7905618\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
